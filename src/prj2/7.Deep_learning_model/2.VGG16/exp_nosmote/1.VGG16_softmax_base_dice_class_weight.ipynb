{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\Data\\ads_fraud_detection\n",
      "c:/Users/Admin/Data/ads_fraud_detection\n"
     ]
    }
   ],
   "source": [
    "import sys,os\n",
    "__script_path=os.path.abspath(globals().get('__file__','.'))\n",
    "__script_dir = os.path.dirname(__script_path)\n",
    "root_dir = os.path.abspath(f'{__script_dir}/../../../..')\n",
    "print(root_dir)\n",
    "for lib in [root_dir][::-1]:\n",
    "    if lib in sys.path:\n",
    "        sys.path.remove(lib)\n",
    "    sys.path.insert(0,lib)\n",
    "from config.config import *\n",
    "from libs.common import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir=f\"{exps_dir}/exp2/exp_adasyn\"\n",
    "if os.path.exists(save_dir) == False: \n",
    "  os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "test_size=0.33\n",
    "seed=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.5317035512094699, 1: 8.385551948051948}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train=pd.read_excel(f'{save_dir}/x_train.xlsx')\n",
    "y_train=pd.read_excel(f'{save_dir}/y_train.xlsx')\n",
    "x_test=pd.read_excel(f'{save_dir}/x_test.xlsx')\n",
    "y_test=pd.read_excel(f'{save_dir}/y_test.xlsx')\n",
    "class_weights_dict=dict(np.load(f'{save_dir}/class_weights_dict.npz',allow_pickle=True))['class_weights_dict']\n",
    "class_weights_dict = {key: value for key, value in class_weights_dict.item().items()}\n",
    "class_weights_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5089, 2) (19305, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def oneHot(arr):\n",
    "    labels = np.array(arr)\n",
    "    encoder = OneHotEncoder(sparse=False)\n",
    "    \n",
    "    labels_reshaped = labels.reshape(-1, 1)\n",
    "    \n",
    "    encoder.fit(labels_reshaped)\n",
    "    \n",
    "    onehot_labels = encoder.transform(labels_reshaped)\n",
    "    return onehot_labels\n",
    "\n",
    "y_train_onehot=oneHot(y_train)\n",
    "y_test_onehot=oneHot(y_test)\n",
    "print(y_test_onehot.shape,y_train_onehot.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Macro F1 score metric.\n",
    "    \"\"\"\n",
    "    y_pred = K.round(y_pred)    \n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)), axis=0)\n",
    "    false_positives = K.sum(K.round(K.clip(y_pred - y_true, 0, 1)), axis=0)\n",
    "    false_negatives = K.sum(K.round(K.clip(y_true - y_pred, 0, 1)), axis=0)    \n",
    "    precision = true_positives / (true_positives + false_positives + K.epsilon())\n",
    "    recall = true_positives / (true_positives + false_negatives + K.epsilon())    \n",
    "    f1_scores = 2 * (precision * recall) / (precision + recall + K.epsilon())    \n",
    "    macro_f1_score = K.mean(f1_scores)\n",
    "    \n",
    "    return macro_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss(y_true, y_pred, alpha=0.25, gamma=2.0):\n",
    "    y_pred = tf.clip_by_value(y_pred, 1e-7, 1 - 1e-7)\n",
    "    pt = tf.where(tf.equal(y_true, 1), y_pred, 1 - y_pred)\n",
    "    loss = -tf.reduce_mean(alpha * tf.pow(1.0 - pt, gamma) * tf.math.log(pt))\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def dice_coef(y_true, y_pred, smooth):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    dice = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return dice\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred, smooth=0.0001):\n",
    "    return 1 - dice_coef(y_true, y_pred, smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_loss(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    tp = tf.reduce_sum(y_true * y_pred, axis=0)\n",
    "    predicted_positives = tf.reduce_sum(y_pred, axis=0)\n",
    "    possible_positives = tf.reduce_sum(y_true, axis=0)\n",
    "    precision = tp / (predicted_positives + tf.keras.backend.epsilon())\n",
    "    recall = tp / (possible_positives + tf.keras.backend.epsilon())\n",
    "    f1 = 2 * (precision * recall) / (precision + recall + tf.keras.backend.epsilon())\n",
    "    f1_macro = tf.reduce_mean(f1)\n",
    "    return 1 - f1_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_loss(y_true, y_pred):\n",
    "    # # Tính toán các loss function riêng lẻ\n",
    "    focal__loss = focal_loss(y_true,y_pred)\n",
    "    f1__loss = f1_loss(y_true,y_pred)\n",
    "    dice__loss = dice_coef_loss(y_true,y_pred)\n",
    "    focal_weight = 0.3\n",
    "    f1_weight = 0.5\n",
    "    dice_weight = 0.2\n",
    "\n",
    "    total_loss = (focal_weight * focal__loss) + (f1_weight * f1__loss) + (dice_weight * dice__loss)\n",
    "\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape =(len(x_train.columns),1)\n",
    "x_input = Input(shape=input_shape)\n",
    "dense_units = 1024\n",
    "learning_rate = 0.0001\n",
    "kernel_size =3\n",
    "filter_size=128\n",
    "\n",
    "\n",
    "# Block 1\n",
    "x = Conv1D(filter_size, kernel_size, activation='relu', padding='same', name='block1_conv1')(x_input)\n",
    "x = Conv1D(filter_size, kernel_size, activation='relu', padding='same', name='block1_conv2')(x)\n",
    "x = MaxPooling1D(2, strides=2, name='block1_pool')(x)\n",
    "\n",
    "# Block 2\n",
    "x = Conv1D(filter_size*2, kernel_size, activation='relu', padding='same', name='block2_conv1')(x)\n",
    "x = Conv1D(filter_size*2, kernel_size, activation='relu', padding='same', name='block2_conv2')(x)\n",
    "x = MaxPooling1D(2, strides=2, name='block2_pool')(x)\n",
    "\n",
    "# Block 3\n",
    "x = Conv1D(filter_size*4, kernel_size, activation='relu', padding='same', name='block3_conv1')(x)\n",
    "x = Conv1D(filter_size*4, kernel_size, activation='relu', padding='same', name='block3_conv2')(x)\n",
    "x = Conv1D(filter_size*4, kernel_size, activation='relu', padding='same', name='block3_conv3')(x)\n",
    "x = MaxPooling1D(2, strides=2, name='block3_pool')(x)\n",
    "\n",
    "# Block 4\n",
    "x = Conv1D(filter_size*8, kernel_size, activation='relu', padding='same', name='block4_conv1')(x)\n",
    "x = Conv1D(filter_size*8, kernel_size, activation='relu', padding='same', name='block4_conv2')(x)\n",
    "x = Conv1D(filter_size*8, kernel_size, activation='relu', padding='same', name='block4_conv3')(x)\n",
    "x = MaxPooling1D(2, strides=2, name='block4_pool')(x)\n",
    "\n",
    "# Block 5\n",
    "x = Conv1D(filter_size*8, kernel_size, activation='relu', padding='same', name='block5_conv1')(x)\n",
    "x = Conv1D(filter_size*8, kernel_size, activation='relu', padding='same', name='block5_conv2')(x)\n",
    "x = Conv1D(filter_size*8, kernel_size, activation='relu', padding='same', name='block5_conv3')(x)\n",
    "x = MaxPooling1D(2, strides=2, name='block5_pool')(x)\n",
    "\n",
    "# x = Flatten(name='flatten')(x)\n",
    "# x = Dense(dense_units, activation='relu', name='fc1')(x)\n",
    "# x = Dense(dense_units, activation='relu', name='fc2')(x)\n",
    "# x = Dense(1, activation='sigmoid', name='predictions')(x)  # Sigmoid for binary classification\n",
    "\n",
    "x = GlobalAveragePooling1D()(x)\n",
    "# x = GlobalMaxPooling1D()(x)\n",
    "x = Dense(2, activation='softmax', name='predictions')(x)  # Sigmoid for binary classification\n",
    "\n",
    "# Create model.\n",
    "model = Model(x_input, x, name='vgg16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss',\n",
    "    min_delta=0.00005,\n",
    "    patience=60,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "model_checkpoint = ModelCheckpoint('best_model', monitor='val_loss', save_best_only=True, save_format='tf')\n",
    "\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=20,\n",
    "    min_lr=0.000001,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate), loss='categorical_crossentropy', metrics=['accuracy',f1_score])\n",
    "# model.compile(optimizer=Adam(lr=learning_rate), loss=f1_loss, metrics=['accuracy',f1_score])\n",
    "# model.compile(optimizer=Adam(lr=learning_rate), loss=focal_loss, metrics=['accuracy',f1_score])\n",
    "model.compile(optimizer=Adam(lr=learning_rate), loss=dice_coef_loss, metrics=['accuracy',f1_score])\n",
    "# model.compile(optimizer=Adam(lr=learning_rate), loss=multi_loss, metrics=['accuracy',f1_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 34, 1)]           0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv1D)       (None, 34, 128)           512       \n",
      "                                                                 \n",
      " block1_conv2 (Conv1D)       (None, 34, 128)           49280     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling1D)  (None, 17, 128)           0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv1D)       (None, 17, 256)           98560     \n",
      "                                                                 \n",
      " block2_conv2 (Conv1D)       (None, 17, 256)           196864    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling1D)  (None, 8, 256)            0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv1D)       (None, 8, 512)            393728    \n",
      "                                                                 \n",
      " block3_conv2 (Conv1D)       (None, 8, 512)            786944    \n",
      "                                                                 \n",
      " block3_conv3 (Conv1D)       (None, 8, 512)            786944    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling1D)  (None, 4, 512)            0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv1D)       (None, 4, 1024)           1573888   \n",
      "                                                                 \n",
      " block4_conv2 (Conv1D)       (None, 4, 1024)           3146752   \n",
      "                                                                 \n",
      " block4_conv3 (Conv1D)       (None, 4, 1024)           3146752   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling1D)  (None, 2, 1024)           0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv1D)       (None, 2, 1024)           3146752   \n",
      "                                                                 \n",
      " block5_conv2 (Conv1D)       (None, 2, 1024)           3146752   \n",
      "                                                                 \n",
      " block5_conv3 (Conv1D)       (None, 2, 1024)           3146752   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling1D)  (None, 1, 1024)           0         \n",
      "                                                                 \n",
      " global_average_pooling1d (  (None, 1024)              0         \n",
      " GlobalAveragePooling1D)                                         \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 2)                 2050      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19622530 (74.85 MB)\n",
      "Trainable params: 19622530 (74.85 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1200\n",
      " 54/302 [====>.........................] - ETA: 2:39 - loss: 0.6980 - accuracy: 0.5182 - f1_score: 0.4002"
     ]
    }
   ],
   "source": [
    "model.fit(x=x_train,y=y_train_onehot,\n",
    "          validation_data=(x_test,y_test_onehot),\n",
    "          batch_size=64,epochs= 1200, callbacks=[early_stopping,lr_scheduler])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.history.history\n",
    "fig,axes=plt.subplots(1,2, figsize=(15,8))\n",
    "axes[0].plot(pd.DataFrame(history['val_accuracy']))\n",
    "axes[0].set_title('Training Process')\n",
    "axes[1].plot(pd.DataFrame(history))\n",
    "axes[1].set_title('Training Process')\n",
    "plt.show()\n",
    "plt.savefig('train.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_labels = np.argmax(y_test_onehot, axis=1)\n",
    "predictions = model.predict(x_test)\n",
    "predictions = np.argmax(predictions, axis=1)\n",
    "accuracy = accuracy_score(y_test_labels, predictions)\n",
    "accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "y_test_labels = np.argmax(y_test_onehot, axis=1)\n",
    "\n",
    "accuracy = accuracy_score(y_test_labels, predictions)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_labels, predictions))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_labels, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dự đoán\n",
    "\n",
    "\n",
    "# Tính ma trận nhầm lẫn\n",
    "cm = confusion_matrix(y_test, predictions,labels=[1,0])\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', xticklabels=[1,0], yticklabels=[1,0])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(15, 15))\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, predictions)\n",
    "    \n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "ax.plot(fpr, tpr, lw=4, color='blue', label='ROC curve (AUC = %0.2f)' % roc_auc)\n",
    "ax.plot([0, 1], [0, 1], color='red', lw=2, linestyle='--')\n",
    "ax.set_xlim([0.0, 1.0])\n",
    "ax.set_ylim([0.0, 1.05])\n",
    "ax.set_xlabel('False Positive Rate', fontsize=12, weight='bold')  \n",
    "ax.set_ylabel('True Positive Rate', fontsize=12, weight='bold')   \n",
    "ax.set_title(f'ROC of Voting',fontsize=20, weight='bold')  \n",
    "ax.legend(loc=\"lower right\", prop={'size': 12, 'weight': 'bold'}) \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
